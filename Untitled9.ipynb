{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhXyoYhBrP/93rJS6OPyLS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirmohammadkalateh/Mental_Health_Lifestyle/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhtAoqT9sTuf",
        "outputId": "faf2d509-687a-45fa-d841-00852bbcb926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch 1/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 26.0941 - mae: 4.3999 - val_loss: 7.8942 - val_mae: 2.3960\n",
            "Epoch 2/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.4607 - mae: 2.3110 - val_loss: 7.2689 - val_mae: 2.3218\n",
            "Epoch 3/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.8640 - mae: 2.2175 - val_loss: 7.1590 - val_mae: 2.3081\n",
            "Epoch 4/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.8679 - mae: 2.2292 - val_loss: 7.1101 - val_mae: 2.3024\n",
            "Epoch 5/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.9469 - mae: 2.2415 - val_loss: 7.0943 - val_mae: 2.3022\n",
            "Epoch 6/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.9978 - mae: 2.2559 - val_loss: 7.0785 - val_mae: 2.2993\n",
            "Epoch 7/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.8247 - mae: 2.2381 - val_loss: 7.0523 - val_mae: 2.2974\n",
            "Epoch 8/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.3703 - mae: 2.1482 - val_loss: 7.0490 - val_mae: 2.2985\n",
            "Epoch 9/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.5751 - mae: 2.1886 - val_loss: 7.0790 - val_mae: 2.3016\n",
            "Epoch 10/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.2817 - mae: 2.1317 - val_loss: 7.0127 - val_mae: 2.2934\n",
            "Epoch 11/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3805 - mae: 2.1479 - val_loss: 7.0148 - val_mae: 2.2910\n",
            "Epoch 12/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3130 - mae: 2.1288 - val_loss: 7.0795 - val_mae: 2.3027\n",
            "Epoch 13/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2066 - mae: 2.1154 - val_loss: 7.0674 - val_mae: 2.3001\n",
            "Epoch 14/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3960 - mae: 2.1655 - val_loss: 7.0272 - val_mae: 2.2966\n",
            "Epoch 15/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1115 - mae: 2.0730 - val_loss: 7.1332 - val_mae: 2.3155\n",
            "Epoch 16/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1520 - mae: 2.1208 - val_loss: 7.0488 - val_mae: 2.3008\n",
            "Epoch 17/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2980 - mae: 2.1239 - val_loss: 7.0608 - val_mae: 2.3007\n",
            "Epoch 18/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0770 - mae: 2.0969 - val_loss: 7.0814 - val_mae: 2.3076\n",
            "Epoch 19/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0549 - mae: 2.0936 - val_loss: 7.0460 - val_mae: 2.3040\n",
            "Epoch 20/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0452 - mae: 2.0881 - val_loss: 7.2565 - val_mae: 2.3354\n",
            "Epoch 21/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0644 - mae: 2.0860 - val_loss: 7.0727 - val_mae: 2.3038\n",
            "Epoch 22/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9136 - mae: 2.0575 - val_loss: 7.0775 - val_mae: 2.3049\n",
            "Epoch 23/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2461 - mae: 2.1348 - val_loss: 7.0943 - val_mae: 2.3039\n",
            "Epoch 24/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1036 - mae: 2.0856 - val_loss: 7.0942 - val_mae: 2.3088\n",
            "Epoch 25/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9437 - mae: 2.0654 - val_loss: 7.1356 - val_mae: 2.3168\n",
            "Epoch 26/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8299 - mae: 2.0467 - val_loss: 7.1441 - val_mae: 2.3181\n",
            "Epoch 27/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1991 - mae: 2.1252 - val_loss: 7.2275 - val_mae: 2.3343\n",
            "Epoch 28/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6878 - mae: 2.0232 - val_loss: 7.2270 - val_mae: 2.3347\n",
            "Epoch 29/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.5769 - mae: 1.9828 - val_loss: 7.2233 - val_mae: 2.3328\n",
            "Epoch 30/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.7531 - mae: 2.0231 - val_loss: 7.2272 - val_mae: 2.3289\n",
            "Epoch 31/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.5440 - mae: 2.0006 - val_loss: 7.2321 - val_mae: 2.3338\n",
            "Epoch 32/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8220 - mae: 2.0579 - val_loss: 7.2048 - val_mae: 2.3242\n",
            "Epoch 33/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6988 - mae: 2.0402 - val_loss: 7.2635 - val_mae: 2.3373\n",
            "Epoch 34/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5813 - mae: 1.9920 - val_loss: 7.2226 - val_mae: 2.3282\n",
            "Epoch 35/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6751 - mae: 2.0286 - val_loss: 7.3456 - val_mae: 2.3454\n",
            "Epoch 36/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6831 - mae: 2.0271 - val_loss: 7.3161 - val_mae: 2.3440\n",
            "Epoch 37/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7837 - mae: 2.0310 - val_loss: 7.2885 - val_mae: 2.3352\n",
            "Epoch 38/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2787 - mae: 1.9507 - val_loss: 7.3475 - val_mae: 2.3436\n",
            "Epoch 39/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3883 - mae: 1.9528 - val_loss: 7.2357 - val_mae: 2.3253\n",
            "Epoch 40/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1889 - mae: 1.9195 - val_loss: 7.3161 - val_mae: 2.3308\n",
            "Epoch 41/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4080 - mae: 1.9685 - val_loss: 7.3505 - val_mae: 2.3470\n",
            "Epoch 42/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2668 - mae: 1.9442 - val_loss: 7.2932 - val_mae: 2.3330\n",
            "Epoch 43/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4588 - mae: 1.9725 - val_loss: 7.4175 - val_mae: 2.3496\n",
            "Epoch 44/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4495 - mae: 1.9717 - val_loss: 7.3884 - val_mae: 2.3416\n",
            "Epoch 45/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3651 - mae: 1.9602 - val_loss: 7.3411 - val_mae: 2.3343\n",
            "Epoch 46/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1317 - mae: 1.9208 - val_loss: 7.4129 - val_mae: 2.3462\n",
            "Epoch 47/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0484 - mae: 1.8928 - val_loss: 7.4527 - val_mae: 2.3475\n",
            "Epoch 48/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0838 - mae: 1.9041 - val_loss: 7.4611 - val_mae: 2.3533\n",
            "Epoch 49/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1231 - mae: 1.9121 - val_loss: 7.4618 - val_mae: 2.3420\n",
            "Epoch 50/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1199 - mae: 1.8864 - val_loss: 7.4628 - val_mae: 2.3437\n",
            "Epoch 51/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1693 - mae: 1.9047 - val_loss: 7.6291 - val_mae: 2.3617\n",
            "Epoch 52/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8565 - mae: 1.8430 - val_loss: 7.5207 - val_mae: 2.3514\n",
            "Epoch 53/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9203 - mae: 1.8448 - val_loss: 7.6484 - val_mae: 2.3728\n",
            "Epoch 54/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8662 - mae: 1.8418 - val_loss: 7.6413 - val_mae: 2.3694\n",
            "Epoch 55/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7467 - mae: 1.8276 - val_loss: 7.6305 - val_mae: 2.3620\n",
            "Epoch 56/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8398 - mae: 1.8378 - val_loss: 7.7715 - val_mae: 2.3941\n",
            "Epoch 57/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7151 - mae: 1.8292 - val_loss: 7.6499 - val_mae: 2.3674\n",
            "Epoch 58/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6154 - mae: 1.7898 - val_loss: 7.6795 - val_mae: 2.3686\n",
            "Epoch 59/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7985 - mae: 1.8392 - val_loss: 7.7290 - val_mae: 2.3746\n",
            "Epoch 60/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5450 - mae: 1.7807 - val_loss: 7.6828 - val_mae: 2.3718\n",
            "Epoch 61/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3699 - mae: 1.7350 - val_loss: 7.7593 - val_mae: 2.3833\n",
            "Epoch 62/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7514 - mae: 1.8356 - val_loss: 7.7701 - val_mae: 2.3789\n",
            "Epoch 63/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5625 - mae: 1.7731 - val_loss: 7.8471 - val_mae: 2.3807\n",
            "Epoch 64/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7131 - mae: 1.8207 - val_loss: 7.8299 - val_mae: 2.3929\n",
            "Epoch 65/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5434 - mae: 1.7688 - val_loss: 8.0178 - val_mae: 2.4128\n",
            "Epoch 66/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6039 - mae: 1.7984 - val_loss: 7.8808 - val_mae: 2.3929\n",
            "Epoch 67/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4559 - mae: 1.7582 - val_loss: 7.9714 - val_mae: 2.3992\n",
            "Epoch 68/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4600 - mae: 1.7607 - val_loss: 7.9646 - val_mae: 2.4003\n",
            "Epoch 69/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.4341 - mae: 1.7538 - val_loss: 7.8949 - val_mae: 2.3864\n",
            "Epoch 70/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.2963 - mae: 1.7198 - val_loss: 7.9925 - val_mae: 2.3997\n",
            "Epoch 71/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2846 - mae: 1.7127 - val_loss: 8.0418 - val_mae: 2.4126\n",
            "Epoch 72/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3562 - mae: 1.7183 - val_loss: 8.0163 - val_mae: 2.4056\n",
            "Epoch 73/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2594 - mae: 1.7165 - val_loss: 8.0612 - val_mae: 2.4084\n",
            "Epoch 74/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1069 - mae: 1.6741 - val_loss: 8.0102 - val_mae: 2.3929\n",
            "Epoch 75/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4429 - mae: 1.7449 - val_loss: 8.1093 - val_mae: 2.4127\n",
            "Epoch 76/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1479 - mae: 1.6852 - val_loss: 8.3172 - val_mae: 2.4334\n",
            "Epoch 77/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1648 - mae: 1.6689 - val_loss: 8.1409 - val_mae: 2.4123\n",
            "Epoch 78/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2198 - mae: 1.6953 - val_loss: 8.2168 - val_mae: 2.4220\n",
            "Epoch 79/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1060 - mae: 1.6792 - val_loss: 8.1653 - val_mae: 2.4175\n",
            "Epoch 80/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0840 - mae: 1.6744 - val_loss: 8.2621 - val_mae: 2.4237\n",
            "Epoch 81/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0358 - mae: 1.6475 - val_loss: 8.3568 - val_mae: 2.4272\n",
            "Epoch 82/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9505 - mae: 1.6356 - val_loss: 8.2726 - val_mae: 2.4196\n",
            "Epoch 83/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0687 - mae: 1.6673 - val_loss: 8.3715 - val_mae: 2.4260\n",
            "Epoch 84/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9430 - mae: 1.6375 - val_loss: 8.4064 - val_mae: 2.4340\n",
            "Epoch 85/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7469 - mae: 1.5931 - val_loss: 8.3629 - val_mae: 2.4288\n",
            "Epoch 86/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8070 - mae: 1.6001 - val_loss: 8.3657 - val_mae: 2.4294\n",
            "Epoch 87/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7953 - mae: 1.5747 - val_loss: 8.3968 - val_mae: 2.4220\n",
            "Epoch 88/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7938 - mae: 1.6030 - val_loss: 8.5224 - val_mae: 2.4427\n",
            "Epoch 89/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8219 - mae: 1.6029 - val_loss: 8.3840 - val_mae: 2.4282\n",
            "Epoch 90/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8572 - mae: 1.6134 - val_loss: 8.4265 - val_mae: 2.4263\n",
            "Epoch 91/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7494 - mae: 1.5825 - val_loss: 8.4802 - val_mae: 2.4345\n",
            "Epoch 92/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6909 - mae: 1.5775 - val_loss: 8.4676 - val_mae: 2.4272\n",
            "Epoch 93/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6695 - mae: 1.5524 - val_loss: 8.5411 - val_mae: 2.4411\n",
            "Epoch 94/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8261 - mae: 1.6027 - val_loss: 8.6004 - val_mae: 2.4416\n",
            "Epoch 95/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7124 - mae: 1.5669 - val_loss: 8.6060 - val_mae: 2.4474\n",
            "Epoch 96/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5391 - mae: 1.5421 - val_loss: 8.7629 - val_mae: 2.4612\n",
            "Epoch 97/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4861 - mae: 1.5273 - val_loss: 8.7002 - val_mae: 2.4492\n",
            "Epoch 98/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5540 - mae: 1.5588 - val_loss: 8.6813 - val_mae: 2.4393\n",
            "Epoch 99/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4094 - mae: 1.4995 - val_loss: 8.6645 - val_mae: 2.4456\n",
            "Epoch 100/100\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5421 - mae: 1.5441 - val_loss: 8.6848 - val_mae: 2.4506\n",
            "\n",
            "Test Loss: 7.8943\n",
            "Test MAE: 2.3535\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "R-squared Score: -0.1662\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv('Mental_Health_Lifestyle_Dataset.csv')\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_cols = ['Country', 'Gender', 'Exercise Level', 'Diet Type', 'Stress Level', 'Mental Health Condition']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "# Prepare features and target\n",
        "X = df.drop(['Happiness Score'], axis=1)\n",
        "y = df['Happiness Score']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build model using Functional API\n",
        "inputs = layers.Input(shape=(X_train.shape[1],))\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train model\n",
        "print(\"Training the model...\")\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f'\\nTest Loss: {test_loss:.4f}')\n",
        "print(f'Test MAE: {test_mae:.4f}')\n",
        "\n",
        "# Calculate R-squared\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "ss_res = np.sum((y_test - y_pred.flatten()) ** 2)\n",
        "ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "r2 = 1 - (ss_res / ss_tot)\n",
        "print(f'R-squared Score: {r2:.4f}')"
      ]
    }
  ]
}